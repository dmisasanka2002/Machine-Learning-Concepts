{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross-Validation in Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical method used to evaluate the performance of a machine learning model. It ensures that the model performs well not only on the training data but also on unseen data, thus preventing overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Key Characteristics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Purpose**: Cross-validation is an **evaluation technique**, not a feature engineering or preprocessing method.\n",
    "2. **Main Idea**: Split the dataset into training and testing sets multiple times to evaluate model performance more reliably.\n",
    "3. **Advantage**: Provides a better estimate of a model’s generalization error compared to a single train-test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cross validation idea.png](../images/cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Why Use Cross-Validation?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Model Validation**: Provides a reliable estimate of model performance.\n",
    "\n",
    "- **Reduces Overfitting**: Ensures the model is not overfitted to the training data.\n",
    "\n",
    "- **Model Selection**: Helps compare the performance of different algorithms.\n",
    "\n",
    "- **Improved Generalization**: Evaluates how well the model performs on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How It Works**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core idea of cross-validation is to divide the dataset into subsets (folds) and perform multiple training and testing cycles to ensure the model is validated on different portions of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Types of Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. **K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is divided into `K` equal-sized subsets (folds).\n",
    "- For each iteration:\n",
    "  - One fold is used as the test set.\n",
    "  - The remaining \\(K-1\\) folds are used for training.\n",
    "- The process is repeated `K` times, and the average performance across all folds is calculated.\n",
    "\n",
    "#### Example Code:\n",
    "```python\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "print(\"Accuracy for each fold:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each fold: [1.         0.96666667 0.93333333 0.93333333 0.96666667]\n",
      "Average Accuracy: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Evaluate model\n",
    "scores = cross_val_score(model, X, y, cv=kf)\n",
    "print(\"Accuracy for each fold:\", scores)\n",
    "print(\"Average Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. **Stratified K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similar to K-Fold but preserves the proportion of classes (target variable) in each fold.\n",
    "\n",
    "- Useful for imbalanced datasets.\n",
    "\n",
    "#### Python Example:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9333333333333333\n",
      "Accuracy: 0.9666666666666667\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Leave-One-Out Cross-Validation (LOOCV)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uses one data point as the validation set and the rest for training.\n",
    "\n",
    "- Repeated for every data point.\n",
    "\n",
    "- Computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Example:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"True:\", y_test, \"Predicted:\", predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [0] Predicted: [0]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [2]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [2]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [2]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [1] Predicted: [1]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [1]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [1]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [1]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n",
      "True: [2] Predicted: [2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"True:\", y_test, \"Predicted:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Hold-Out Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset is split into separate training and testing sets.\n",
    "\n",
    "- Simpler but prone to bias if the split isn't representative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Example:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Time Series Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used for time-dependent data.\n",
    "\n",
    "- Splits the data sequentially to respect temporal order.\n",
    "\n",
    "- Avoids \"data leakage\" from future observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Example:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2972972972972973\n",
      "Accuracy: 0.6486486486486487\n",
      "Accuracy: 0.7567567567567568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluating Cross-Validation Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing cross-validation, metrics such as accuracy, precision, recall, or F1-score are averaged across all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Accuracy per fold:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **cross_val_score(model, X, y, cv=cv)** : return the score values for each datasets.\n",
    "  - *model* : Machine learning model\n",
    "  - *X* : 2D `x` values of the dataset.\n",
    "  - *y* : target (y) values of the dataset.\n",
    "  - *cv* : Number of split data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy per fold: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
      "Mean Accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Accuracy per fold:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Advantages & Disadvantages of Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of Cross-Validation\n",
    "\n",
    "- Efficient use of data for training and testing.\n",
    "\n",
    "- Provides more reliable performance estimates.\n",
    "\n",
    "- Reduces variance in evaluation compared to a single train-test split.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages of Cross-Validation\n",
    "\n",
    "- Computationally Intensive:\n",
    "\n",
    "  - Requires training the model multiple times.\n",
    "\n",
    "- Complexity:\n",
    "\n",
    "  - Difficult to implement in some scenarios like time-series data.\n",
    "\n",
    "- Bias-Variance Tradeoff:\n",
    "\n",
    "  - LOOCV has high variance, while K-Fold might introduce some bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Mathematical Equations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For K-Fold Cross-Validation, the average score across all folds is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Score}_{\\text{avg}} = \\frac{1}{K} \\sum_{i=1}^{K} \\text{Score}_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- K = Number of folds.\n",
    "\n",
    "- $\\text{Score}_i$​ = Performance metric (e.g., accuracy) for the $i^{th}$ fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparison of Cross-Validation Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method              |   Strengths                          | Weaknesses                                                    |\n",
    "|---------------------|--------------------------------------|---------------------------------------------------------------|\n",
    "|K-Fold               | Reliable, balances bias and variance |Computational cost for large datasets                          |\n",
    "|Stratified K-Fold    | Handles imbalanced datasets          |Similar to K-Fold limitations                                  |\n",
    "|Leave-One-Out (LOOCV) | Best for small datasets             |Very computationally expensive                                 |\n",
    "|Hold-Out Validation  |Simple and fast                       |Results depend on the split                                    |\n",
    "|Time Series          |Respects time order                   |Limited to sequential data                                     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a cornerstone technique in machine learning that ensures robust and unbiased evaluation of model performance, making it essential for any ML workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
