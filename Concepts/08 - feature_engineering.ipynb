{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Engineering in Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is the process of selecting, modifying, or creating features (input variables) that enhance the performance of machine learning models. It plays a crucial role in the success of any machine learning project by improving model accuracy and reducing computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **What is a Feature?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A **feature** is an individual measurable property or characteristic of a phenomenon being observed.\n",
    "- Features serve as inputs to machine learning models.\n",
    "- Examples:\n",
    "  - For a house price prediction model, features might include the size of the house, number of bedrooms, and location.\n",
    "  - For a text classification task, features might be word counts or TF-IDF scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Importance of Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Improves model performance by providing more informative inputs.\n",
    "- Reduces overfitting by eliminating irrelevant or redundant features.\n",
    "- Simplifies the problem by reducing dimensionality.\n",
    "- Enhances interpretability of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. **Types of Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Feature Engineering Tecniques.png](../images/demention_reduction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Feature Selection\n",
    "\n",
    "- The process of identifying and retaining only the **most relevant features** to improve model performance and reduce complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filter Methods**:\n",
    "   - Use statistical tests to rank features.\n",
    "   - **Examples**: Chi-Square Test, ANOVA, Correlation Coefficient.\n",
    "\n",
    "2. **Wrapper Methods**:\n",
    "   - Use a machine learning model to evaluate feature subsets.\n",
    "   - **Examples**: Forward Selection, Backward Elimination, Recursive Feature Elimination (RFE).\n",
    "\n",
    "3. **Embedded Methods**:\n",
    "   - Features are selected during the model training process.\n",
    "   - **Examples**: Lasso Regression, Decision Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Implementation: Feature Selection with Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [ True False  True]\n",
      "Feature Rankings:  [1 2 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Example data\n",
    "X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "y = [0, 1, 0]\n",
    "\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, n_features_to_select=2)\n",
    "fit = rfe.fit(X, y)\n",
    "print(f\"Selected Features: {fit.support_}\")\n",
    "print(\"Feature Rankings: \", fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[More About Feature Selection](./8.1%20-%20feature_selection_methods.ipynb)\n",
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Extraction\n",
    "- The process of creating new features from raw data to improve its representation.\n",
    "- [Principal Component Analysis (PCA)](../Unsupervised%20Learning/05%20-%20Principal%20Component%20Analysis%20(PCA).ipynb) is widly used in feature extraction as a dimensionality-reduction technique.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Text Data**:\n",
    "  - Bag of Words (BoW), TF-IDF, Word Embeddings.\n",
    "- **Image Data**:\n",
    "  - Edge detection, feature maps using CNNs.\n",
    "- **Time Series Data**:\n",
    "  - Extracting trends, seasonality, and autocorrelations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feature Transformation\n",
    "- Modifying features to make them suitable for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Scaling**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   26, 50000],\n",
       "       [   29, 70000],\n",
       "       [   34, 55000],\n",
       "       [   31, 41000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [26, 50000],\n",
    "    [29, 70000],\n",
    "    [34, 55000],\n",
    "    [31, 41000]\n",
    "])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **Normalization**: Scales data to a range of [0, 1].\n",
    "   <br><br>\n",
    "   ![Normalization.png](../images/normalization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.31034483],\n",
       "       [0.375     , 1.        ],\n",
       "       [1.        , 0.48275862],\n",
       "       [0.625     , 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(data)\n",
    "\n",
    "normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **Standardization**: Centers data to have mean 0 and standard deviation 1. <br><br>\n",
    "   ![Standardization.png](../images/standardization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.37198868, -0.3805212 ],\n",
       "       [-0.34299717,  1.52208478],\n",
       "       [ 1.37198868,  0.0951303 ],\n",
       "       [ 0.34299717, -1.23669388]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(data)\n",
    "\n",
    "standardized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Log Transformation**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **Reduces skewness in data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.29583687, 10.81979828],\n",
       "       [ 3.40119738, 11.15626481],\n",
       "       [ 3.55534806, 10.91510665],\n",
       "       [ 3.4657359 , 10.62135174]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = np.log(data + 1)\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Polynomial Features**:\n",
    "   - **Generate higher-degree features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  4.]\n",
      " [ 1.  3.  9.]\n",
      " [ 1.  4. 16.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = [[2], [3], [4]]\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "print(X_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Encoding Categorical Variables**:\n",
    "[Read More](05%20-%20data_preparation.ipynb#encoding-categorical-variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - **One-Hot Encoding**:\n",
    "     ```python\n",
    "     from sklearn.preprocessing import OneHotEncoder\n",
    "     encoder = OneHotEncoder()\n",
    "     encoded_data = encoder.fit_transform(data).toarray()\n",
    "     ```\n",
    "   - **Label Encoding**:\n",
    "     ```python\n",
    "     from sklearn.preprocessing import LabelEncoder\n",
    "     encoder = LabelEncoder()\n",
    "     encoded_labels = encoder.fit_transform(labels)\n",
    "     ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. **Data Splitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing data into training, validation, and testing datasets is critical for evaluating model performance and avoiding overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training Set\n",
    "- Used to train the model.\n",
    "- Typically constitutes 60-80% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Validation Set\n",
    "- Used to tune hyperparameters and evaluate model performance during training.\n",
    "- Typically constitutes 10-20% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Testing Set\n",
    "- Used to evaluate model performance on unseen data.\n",
    "- Typically constitutes 10-20% of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. **Challenges in Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Curse of Dimensionality**: High-dimensional data can lead to overfitting.\n",
    "- **Domain Knowledge Dependency**: Requires understanding of the dataset and problem domain.\n",
    "- **Computational Complexity**: Large datasets can make feature engineering time-consuming.\n",
    "- **Collinearity**: Highly correlated features can degrade model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. **Best Practices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Understand the dataset and domain thoroughly.\n",
    "2. Visualize features to identify patterns and outliers.\n",
    "3. Use automated tools like `sklearn.feature_selection` for efficiency.\n",
    "4. Experiment with different feature sets to find the optimal configuration.\n",
    "5. Regularly validate the impact of engineered features on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. **Advanced Topics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering for Deep Learning\n",
    "- Use **Convolutional Neural Networks (CNNs)** for image feature extraction.\n",
    "- Use **Recurrent Neural Networks (RNNs)** for sequential data like time series or text.\n",
    "\n",
    "### Automated Feature Engineering\n",
    "- Tools: `FeatureTools`, `Auto-Sklearn`, `H2O.ai`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Type                   | Examples                              | Libraries/Tools               |\n",
    "|------------------------|---------------------------------------|-------------------------------|\n",
    "| Feature Selection      | RFE, Lasso, Chi-Square               | Scikit-learn, Statsmodels     |\n",
    "| Feature Extraction     | TF-IDF, CNN Feature Maps             | Scikit-learn, TensorFlow      |\n",
    "| Feature Transformation | Scaling, Polynomial Features         | Scikit-learn, NumPy           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Scikit-learn Feature Engineering Guide](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "- [FeatureTools Documentation](https://www.featuretools.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
